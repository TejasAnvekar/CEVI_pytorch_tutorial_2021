{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5091e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "458f3760",
   "metadata": {},
   "source": [
    "# Pytorch Data Loader\n",
    "#####  $\\hspace{350pt}$  anvekartejas@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284bc65c",
   "metadata": {},
   "source": [
    "## Loading Data with Structured Folders\n",
    "\n",
    "\n",
    " $\\textbf{Dataset}\\\\ \\hspace{20pt}{|}  \\text{class1} --- \\text{class1_0.png}\\\\  \\hspace{72pt} \\text{class1_1.png}\\\\\n",
    " \\\\  \\hspace{20pt}{|} \\text{class2} --- \\text{class2_0.png}\\\\  \\hspace{72pt} \\text{class2_1.png}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3fcfbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "449a7b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating class for custom dataloader\n",
    "\n",
    "class customloader(Dataset):   ##inherited custom dataset class\n",
    "    def __init__(self,root,transforms=None):\n",
    "        super(customloader,self).__init__()   ## overwrite args\n",
    "        \n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        \n",
    "        self.folders_path = [os.path.join(self.root,x) for x in os.listdir(self.root)]  ##list comprehension for storing root-->folder path in a list\n",
    "        self.folders_path.sort()     ## only for linux\n",
    "        \n",
    "        \n",
    "        self.image_path = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for i in range(len(self.folders_path)):     ## loop through all folders\n",
    "            x = os.listdir(self.folders_path[i])   \n",
    "            for j in range(len(x)):                 ## loop through all images in each sub folders \n",
    "                k = os.path.join(self.folders_path[i],x[j])    #store image path \n",
    "                self.image_path.append(k)\n",
    "                self.labels.append(int(i))                    # store labels\n",
    "           \n",
    "        self.image_path.sort()    ## only for linux\n",
    "        self.labels.sort()        ## only for linux\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_path)    ##over write len method to give iterable len of this obj\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        assert len(self.image_path) == len(self.labels),\"labels size doesnt match with number of images\"\n",
    "        \n",
    "        image = cv2.imread(self.image_path[index])   ## read img of specific image\n",
    "        label = np.array(self.labels[index])        ## read label of specific label\n",
    "        \n",
    "        image = np.array(image)\n",
    "\n",
    "\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)     ## apply custom tranformations\n",
    "        \n",
    "        \n",
    "        return (image,label)   ## return tuble of image and label whenever iterated\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece6c187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images:  50000\n",
      "torch.Size([16, 3, 32, 32]) torch.Size([16]) tensor([7, 5, 9, 4, 2, 1, 9, 0, 5, 0, 8, 9, 0, 1, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "## unit test block\n",
    "\n",
    "\n",
    "data = customloader(root=\"/home/tejas/STD_DATESETS/Cifar-10/Train/Original\",transforms = transforms.ToTensor())\n",
    "print(\"total images: \",len(data))\n",
    "\n",
    "loader = DataLoader(data,batch_size=16,shuffle=True,num_workers=6)\n",
    "\n",
    "for idx ,(x,y) in  enumerate(loader):\n",
    "    print(x.shape,y.shape,y)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49559820",
   "metadata": {},
   "source": [
    "## Loading Data with paths and labels in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3379091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a505790",
   "metadata": {},
   "outputs": [],
   "source": [
    "## customdata loader from csv\n",
    "\n",
    "class customcsv(Dataset):\n",
    "    def __init__(self,csv_path,transforms=None):\n",
    "        super(customcsv,self).__init__()\n",
    "        \n",
    "        self.csv = pd.read_csv(csv_path)      ## read csv\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.csv)+1\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        image = cv2.imread(self.csv.iloc[index,0])   ## read img of specific image \"image path are in column 0\"\n",
    "        label = np.array(self.csv.iloc[index,1])        ## read label of specific label\n",
    "        \n",
    "        image = np.array(image)\n",
    "\n",
    "\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)     ## apply custom tranformations\n",
    "        \n",
    "        \n",
    "        return (image,label)   ## return tuble of image and label whenever iterated\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbfa5e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images:  50000\n",
      "torch.Size([16, 3, 32, 32]) torch.Size([16]) tensor([3, 5, 8, 7, 9, 4, 4, 1, 9, 7, 7, 8, 8, 1, 9, 7])\n"
     ]
    }
   ],
   "source": [
    "## unit test block\n",
    "\n",
    "\n",
    "data = customcsv(csv_path=\"/home/tejas/Pytorch_tutorial/data.csv\",transforms = transforms.ToTensor())\n",
    "print(\"total images: \",len(data))\n",
    "\n",
    "loader = DataLoader(data,batch_size=16,shuffle=True,num_workers=6)\n",
    "\n",
    "for idx ,(x,y) in  enumerate(loader):\n",
    "    print(x.shape,y.shape,y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d1270",
   "metadata": {},
   "source": [
    "# Building ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb9610e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf2354e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self,inp,num_classes=10,layers=[1000,500,200,100]):\n",
    "        super().__init__()\n",
    "        self.FC = nn.ModuleList()   ##Model as list initialization\n",
    "        \n",
    "        for layer in layers:\n",
    "            self.FC.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(inp,layer),    ## linear layer\n",
    "                    nn.ReLU(inplace=False),               ## Retified Linaer unit activation\n",
    "                    nn.Dropout(0.2,inplace=False)          ## 1D drop out with 20% prob\n",
    "                \n",
    "                )\n",
    "            )\n",
    "            \n",
    "            inp=layer\n",
    "            \n",
    "        self.last_embedding = nn.Sequential(nn.Linear(layers[-1],num_classes),nn.Softmax(dim=1))  ## last imbedding layer\n",
    "        \n",
    "    def forward(self,x):                  ## function that computes tensor when sent through\n",
    "        for l in self.FC:\n",
    "            x = l(x)                     ## unpack module list and start dynamic graph as per args\n",
    "            \n",
    "        return self.last_embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b31bdef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN(\n",
      "  (FC): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=2000, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=1000, out_features=500, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=500, out_features=200, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (last_embedding): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=5, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "\n",
      " torch.Size([1, 784]) torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "#unit testing\n",
    "def testANN():\n",
    "    inp = torch.randn((1,784)).cuda()\n",
    "    model = ANN(inp=784,num_classes=5,layers=[2000,1000,500,200]).cuda()\n",
    "    out = model(inp)\n",
    "    \n",
    "    print(model)\n",
    "    print(\"\\n\",inp.shape,out.shape)\n",
    "    \n",
    "testANN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4bdf5c",
   "metadata": {},
   "source": [
    "## Loss Function,optimizers and hyperameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b23a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANN(inp=32*32*3,num_classes=10,layers=[2000,1000,500,200]).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=2e-4,betas=(0.5,0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35659b9",
   "metadata": {},
   "source": [
    "## Data Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60a4c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = customloader(root=\"/home/tejas/Pytorch_tutorial/cifar10_example/train\",transforms = transforms.ToTensor())\n",
    "test_data = customloader(root=\"/home/tejas/Pytorch_tutorial/cifar10_example/test\",transforms = transforms.ToTensor())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data,shuffle=True,batch_size=8,num_workers=2)\n",
    "test_loader = DataLoader(test_data,shuffle=False,batch_size=10000,num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8806d5",
   "metadata": {},
   "source": [
    "## Training and testing loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da838081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        data = data.reshape(data.shape[0],-1)\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(data),\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.reshape(data.shape[0],-1)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(\n",
    "                output, target, reduction=\"sum\"\n",
    "            ).item()  # sum up batch loss\n",
    "            pred = output.argmax(\n",
    "                dim=1, keepdim=True\n",
    "            )  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss,\n",
    "            correct,\n",
    "            len(test_loader.dataset),\n",
    "            100.0 * correct / len(test_loader.dataset),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a691dd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/100 (0%)]\tLoss: 2.305349\n",
      "Train Epoch: 0 [80/100 (77%)]\tLoss: 2.302638\n",
      "\n",
      "Test set: Average loss: 2.3021, Accuracy: 12/100 (12%)\n",
      "\n",
      "Train Epoch: 1 [0/100 (0%)]\tLoss: 2.305270\n",
      "Train Epoch: 1 [80/100 (77%)]\tLoss: 2.303216\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 16/100 (16%)\n",
      "\n",
      "Train Epoch: 2 [0/100 (0%)]\tLoss: 2.302628\n",
      "Train Epoch: 2 [80/100 (77%)]\tLoss: 2.308480\n",
      "\n",
      "Test set: Average loss: 2.3008, Accuracy: 16/100 (16%)\n",
      "\n",
      "Train Epoch: 3 [0/100 (0%)]\tLoss: 2.300733\n",
      "Train Epoch: 3 [80/100 (77%)]\tLoss: 2.296592\n",
      "\n",
      "Test set: Average loss: 2.2993, Accuracy: 12/100 (12%)\n",
      "\n",
      "Train Epoch: 4 [0/100 (0%)]\tLoss: 2.311723\n",
      "Train Epoch: 4 [80/100 (77%)]\tLoss: 2.336599\n",
      "\n",
      "Test set: Average loss: 2.2968, Accuracy: 10/100 (10%)\n",
      "\n",
      "Train Epoch: 5 [0/100 (0%)]\tLoss: 2.307407\n",
      "Train Epoch: 5 [80/100 (77%)]\tLoss: 2.310049\n",
      "\n",
      "Test set: Average loss: 2.2933, Accuracy: 10/100 (10%)\n",
      "\n",
      "Train Epoch: 6 [0/100 (0%)]\tLoss: 2.303737\n",
      "Train Epoch: 6 [80/100 (77%)]\tLoss: 2.322188\n",
      "\n",
      "Test set: Average loss: 2.2868, Accuracy: 13/100 (13%)\n",
      "\n",
      "Train Epoch: 7 [0/100 (0%)]\tLoss: 2.270475\n",
      "Train Epoch: 7 [80/100 (77%)]\tLoss: 2.243638\n",
      "\n",
      "Test set: Average loss: 2.2778, Accuracy: 12/100 (12%)\n",
      "\n",
      "Train Epoch: 8 [0/100 (0%)]\tLoss: 2.335964\n",
      "Train Epoch: 8 [80/100 (77%)]\tLoss: 2.239757\n",
      "\n",
      "Test set: Average loss: 2.2762, Accuracy: 13/100 (13%)\n",
      "\n",
      "Train Epoch: 9 [0/100 (0%)]\tLoss: 2.320010\n",
      "Train Epoch: 9 [80/100 (77%)]\tLoss: 2.288041\n",
      "\n",
      "Test set: Average loss: 2.2718, Accuracy: 14/100 (14%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_cuda =  torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    train(model,device,train_loader,optimizer,epoch)\n",
    "    test(model,device,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93036117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
